{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset in a Nutshell - Part 3: Neutron Data\n",
    "\n",
    " This is a solution for the final exercise in [Dataset in a Nutshell - Part 3](demo-part3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import dataset as ds\n",
    "from dataset import Dim, Coord, Data, Attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converters from Mantid workspaces\n",
    "\n",
    "For convenience and testing, very basic converters from Mantid's `EventWorkspace` and `Workspace2D` to `Dataset` are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mantid.simpleapi as mantid\n",
    "import dataset.compat.mantid as mantidcompat\n",
    "filename = 'PG3_4844_event.nxs'\n",
    "filename_vanadium = 'PG3_4866_event.nxs'\n",
    "\n",
    "# Create a list of banks (one dataset per bank)\n",
    "banks = []\n",
    "bankids = [124, 144, 164, 184]\n",
    "for bankid in bankids:\n",
    "    bank = 'bank{}'.format(bankid)\n",
    "    sampleWS = mantid.LoadEventNexus(filename, BankName=bank)\n",
    "    vanadiumWS = mantid.LoadEventNexus(filename_vanadium, BankName=bank)\n",
    "\n",
    "    d = mantidcompat.to_dataset(sampleWS, name='sample', drop_pulse_times=False)\n",
    "    d.merge(mantidcompat.to_dataset(vanadiumWS, name='vanadium', drop_pulse_times=True))\n",
    "    banks.append(d)\n",
    "\n",
    "# Concatenate all banks into a single dataset\n",
    "d = banks[0]\n",
    "for d2 in banks[1:]:\n",
    "    d = ds.concatenate(d, d2, Dim.Row)\n",
    "\n",
    "# We add a new coordinate for the new dimension. Strictly speaking this is not necessary,\n",
    "# but if we want to plot directly it is convenient.\n",
    "d[Coord.Row] = ([Dim.Row], bankids)\n",
    "# Concatenation created a 2D array of spectrum numbers. This is currently not supported by\n",
    "# the plot helper, so we create a 1D fake spectrum number (restarting at 0 for every bank).\n",
    "# 1078 is the number of pixels per bank.\n",
    "d[Coord.SpectrumNumber] = ([Dim.Position], np.arange(1078))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested data in a dataset: Instrument geometry and event lists\n",
    "\n",
    "Some of the content of the workspaces is not easily representable as a plain multi-dimensional array.\n",
    "A number of variables in the dataset obtained from the workspace thus have item type `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Coord.ComponentInfo` is similar to the `ComponentInfo` in Mantid.\n",
    " It contains information about the components in the beamline.\n",
    " For the time being, it only contains the positions for source and sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[Coord.ComponentInfo].scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus note 1:\n",
    " For the most part, the structure of `ComponentInfo` (and `DetectorInfo`) in Mantid is easily represented by a `Dataset`, i.e., very little change is required.\n",
    " For example, scanning is simply handled by an extra dimension of, e.g., the position and rotation variables.\n",
    " By using `Dataset` to handle this, we can use exactly the same tools and do not need to implement or learn a new API.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Data.Events` is the equivalent to a vector of `EventList`s in Mantid.\n",
    " Here, we chose to represent an event list as a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[Data.Events, 'sample'].data[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could in principle also choose other, more efficient, event storage formats.\n",
    " At this point, using a dataset as an event list is convenient because it lets us reuse the same functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = d[Data.Events, 'sample'].data[500]\n",
    "d[Data.Events, 'sample'].data[500] = ds.sort(events, Data.Tof)[Dim.Event, 100:-100]\n",
    "ds.table(d[Data.Events, 'sample'].data[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From events to histogram\n",
    "\n",
    "We histogram the event data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.events.sort_by_tof(d)\n",
    "coord = ds.Variable(Coord.Tof, [Dim.Tof], np.arange(1000.0, 20000.0, 50.0))\n",
    "binned = ds.histogram(d, coord)\n",
    "d.merge(binned)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We need to specify an extra coordinate here\n",
    "ds.plot(d.subset[Data.Value, 'sample'], axes=[Coord.Row, Coord.SpectrumNumber, Coord.Tof])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake instrument view\n",
    "\n",
    "Just for fun, we can quickly generate a crude \"instrument view\".\n",
    "In this case this works since we have only a single panel.\n",
    "If there were multiple panels, they could be handled as an extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = ds.Dataset()\n",
    "# 154 and 7 are the extents of the panel\n",
    "# We need to add Dim.Row with extent 4 as the new outermost dimension\n",
    "panel[Data.Value, 'sample'] = d[Data.Value, 'sample'].reshape([Dim.Row, Dim.X, Dim.Y, Dim.Tof], (4, 154, 7, 379))\n",
    "panel[Coord.Tof] = d[Coord.Tof]\n",
    "# Note that the scale is meaningless, could use real instrument parameters\n",
    "panel[Coord.X] = ([Dim.X], np.arange(154))\n",
    "panel[Coord.Y] = ([Dim.Y], np.arange(7))\n",
    "\n",
    "# Showing panel 4\n",
    "ds.plot(panel[Dim.Tof, 180:260][Dim.Row, 3], axes=[Coord.Tof, Coord.Y, Coord.X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing panel 3, note the different time-of-flight range\n",
    "ds.plot(panel[Dim.Tof, 260:300][Dim.Row, 2], axes=[Coord.Tof, Coord.Y, Coord.X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(d[Data.Events, 'sample'])\n",
    "del(d[Data.Events, 'vanadium'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitors\n",
    "\n",
    "Monitors are not handled by the Mantid converter yet, but we can add some fake ones to demonstrate the versatility  of `Dataset`.\n",
    "Storing each monitor as a separate variable that contains a nested dataset gives us complete freedom an flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram-mode beam monitor\n",
    "beam = ds.Dataset()\n",
    "beam[Coord.Tof] = ([Dim.Tof], np.arange(1001.0))\n",
    "beam[Data.Value] = ([Dim.Tof], np.random.rand(1000))\n",
    "beam[Data.Variance] = beam[Data.Value]\n",
    "beam[Data.Value].unit = ds.units.counts\n",
    "beam[Data.Variance].unit = ds.units.counts * ds.units.counts\n",
    "\n",
    "# Event-mode transmission monitor\n",
    "transmission = ds.Dataset()\n",
    "transmission[Data.Tof] = ([Dim.Event], 20000.0 * np.random.rand(123456))\n",
    "\n",
    "# Beam profile monitor\n",
    "profile = ds.Dataset()\n",
    "profile[Coord.X] = ([Dim.X], np.arange(-0.1, 0.11, 0.01))\n",
    "profile[Coord.Y] = ([Dim.Y], np.arange(-0.1, 0.11, 0.01))\n",
    "profile[Data.Value] = ([Dim.Y, Dim.X], np.random.rand(20, 20))\n",
    "for i in 1,2,3,4:\n",
    "    profile[Dim.X, i:-i][Dim.Y, i:-i] += 1.0\n",
    "profile[Data.Value].unit = ds.units.counts\n",
    "\n",
    "ds.plot(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[Coord.Monitor, 'transmission'] = ([], transmission)\n",
    "d[Coord.Monitor, 'beam'] = ([], beam)\n",
    "d[Coord.Monitor, 'profile'] = ([], profile)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    " Normalize the sample data to the \"beam\" monitor.\n",
    "\n",
    " ### Solution 1\n",
    " The binning of the monitor does not match that of the data, so we need to rebin it before the division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_over_beam = d.subset['sample'] / ds.rebin(d[Coord.Monitor, 'beam'].scalar, d[Coord.Tof])\n",
    "sample_over_beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_scan = ds.concatenate(d, d * 0.8, Dim.Temperature)\n",
    "temp_scan = ds.concatenate(temp_scan, temp_scan * 0.64, Dim.Temperature)\n",
    "temp_scan[Coord.Temperature] = ([Dim.Temperature], [273.0, 180.0, 100.0, 4.3])\n",
    "temp_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coord.Row specified as additional dimension, we have two sliders now\n",
    "ds.plot(temp_scan.subset[Data.Value, 'sample'][Dim.Position, 20:], axes=[Coord.Row, Coord.SpectrumNumber, Coord.Temperature, Coord.Tof])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing out a single panel\n",
    "ds.plot(temp_scan.subset[Data.Value, 'sample'][Dim.Position, 500][Dim.Row, 3], collapse=Dim.Temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ds.convert(d, Dim.Tof, Dim.DSpacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cannot handle ragged coordinates at this point, rebin to edges of first spectrum\n",
    "# Need to slice also Dim.Row to obtain 1D axis for rebinning\n",
    "d = ds.rebin(d, d[Coord.DSpacing][Dim.Position, 0][Dim.Row, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 coordinates now, this is now a plot with slider\n",
    "ds.plot(d.subset[Data.Value, 'sample'], axes=[Coord.Row, Coord.SpectrumNumber, Coord.DSpacing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Second plot moved to different cell (two plots with slider in the same cell not working currently)\n",
    "ds.plot(d.subset[Data.Value, 'vanadium'], axes=[Coord.Row, Coord.SpectrumNumber, Coord.DSpacing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing and normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summed = ds.sum(d, Dim.Position)\n",
    "# Using a loop + slicing to obtain separate plots. Otherwise we would get a 2D plot which\n",
    "# is not so useful in this case.\n",
    "for bank in [0,1,2,3]:\n",
    "    ds.plot(summed[Dim.Row, bank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = summed.subset['sample'] / summed.subset['vanadium']\n",
    "# Using the `collapse` option to get a unified plot\n",
    "ds.plot(normalized, collapse=Dim.Row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (advanced)\n",
    "\n",
    "Instead of loading only a single bank, load multiple, e.g., `bank124`, `bank144`, `bank164`, and `bank184`.\n",
    "Modify everything in this notebook to work with the new multi-bank data, obtaining a separate focussed diffraction spectrum for each bank.\n",
    "\n",
    "There is more than one option to solve this:\n",
    "1. Concatenate the loaded data into a single dataset, resulting in more or larger dimensions.\n",
    "2. Merge the loaded data into a single dataset, resulting in differently named variables for each bank.\n",
    "3. Call the existing code as-is for each bank, working, e.g., for a Python `list` of datasets.\n",
    "\n",
    "Each of the approaches has its advantages and drawbacks.\n",
    "\n",
    "Here we recommend option 1, which in itself can be implemented in one of two ways:\n",
    "- Concatenate along a new dimension (`Dim.Bank` and `Coord.Bank` is not supported currently, use, e.g., `Dim.Row` instead).\n",
    "- Concatenate along the existing dimension `Dim.Position`.\n",
    "\n",
    "*Note: You will likely experience some small problems with plotting, in particular issues with multi-dimensional coordinates in the first case (we suggest to slice manually until this is supported), and large gaps in the second case (can be avoided by adding a helper-coordinate).*\n",
    "\n",
    "*Bonus note for option 3: Unlike Mantid workspaces, datasets can safely be used in combination with Python containers. Do not try this with workspaces, since they are entangled with the `AnalysisDataService`.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
